{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Pensieve™\n",
    "An Enhanced Deep Residual (EDSR) Information Maximizing Variational Auto-Encoder (InfoVAE) with Group Normalization (GN), Residual Bottleneck Attention Modules (RBAM), Efficient Sub-Pixel Convolution Super-Resolution (ESPCN), and Perceptual Similarity Loss (SSIM)\n",
    "\n",
    "<table><tr>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540551741.4923084-final.gif'></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540552110.470284-final.gif'></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-080.gif\"></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540552122.395882-final.gif'></td>\n",
    "<td><img src='https://s3.amazonaws.com/neurokinetikz/latent-animation-1540551578.5925505-final.gif'></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1705.07202\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-1.png\">\n",
    "\n",
    "Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. One drawback of VAE is that it generates blurry images due to its Gaussianity assumption and thus L2 loss. To allow the generation of high quality images by VAE, we increase the capacity of decoder network by employing residual blocks and skip connections, which also enable efficient optimization. To overcome the limitation of L2 loss, we propose to generate images in a multi-stage manner from coarse to fine. \n",
    "\n",
    "In the simplest case, the proposed multi-stage VAE divides the decoder into two components in which the second component generates refined images based on the course images generated by the first component. Since the second component is independent of the VAE model, it can employ other loss functions beyond the L2 loss and different model architectures. \n",
    "\n",
    "The proposed framework can be easily generalized to contain more than two components. Experiment results on the MNIST and CelebA datasets demonstrate that the proposed multi-stage VAE can generate sharper images as compared to those from the original VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from libs import utils, gif\n",
    "from libs.group_norm import GroupNormalization\n",
    "from libs.variance_pooling import GlobalVariancePooling2D\n",
    "\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.layers import Input, Flatten, Reshape, Add, Multiply, Activation, Lambda\n",
    "from keras.layers import Dense, Conv2D, DepthwiseConv2D, SeparableConv2D\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras_contrib.losses import DSSIMObjective\n",
    "from keras_contrib.layers.convolutional import SubPixelUpscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = 'roadtrip'\n",
    "\n",
    "SIZE = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "SCALE_FACTOR = 2\n",
    "\n",
    "FEATURES = SIZE*SIZE*CHANNELS\n",
    "FEATURES_2X = SCALE_FACTOR*SIZE*SCALE_FACTOR*SIZE*CHANNELS\n",
    "\n",
    "MODEL_NAME = DIRECTORY+'-'+str(SIZE)+'-'+str(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images:\t184\n",
      "Loading images:\t184\n",
      "MODEL:  roadtrip-64-1547425268.865832\n",
      "IMGS:  (184, 64, 64, 3) (184, 128, 128, 3)\n",
      "FLAT:  (184, 12288) (184, 49152)\n",
      "SAMPLES:  (9, 12288) (9, 49152)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "imgs, xs, ys  = utils.load_images(directory=\"imgs/\"+DIRECTORY,rx=SIZE,ry=SIZE)\n",
    "imgs_2x, xs_2x, ys_2x = utils.load_images(directory=\"imgs/\"+DIRECTORY,rx=SCALE_FACTOR*SIZE,ry=SCALE_FACTOR*SIZE)\n",
    "\n",
    "# normalize pixels\n",
    "IMGS = imgs/127.5 - 1\n",
    "FLAT = np.reshape(IMGS,(-1,FEATURES))\n",
    "\n",
    "IMGS_2X = imgs_2x/127.5 - 1\n",
    "FLAT_2X = np.reshape(IMGS_2X,(-1,FEATURES_2X)) \n",
    "\n",
    "SAMPLES =  np.random.permutation(FLAT)[:9]\n",
    "SAMPLES_2X =  np.random.permutation(FLAT_2X)[:9]\n",
    "\n",
    "TOTAL_BATCH = IMGS.shape[0]\n",
    "\n",
    "# print shapes\n",
    "print(\"MODEL: \",MODEL_NAME)\n",
    "print(\"IMGS: \",IMGS.shape,IMGS_2X.shape)\n",
    "print(\"FLAT: \",FLAT.shape,FLAT_2X.shape)\n",
    "print(\"SAMPLES: \",SAMPLES.shape,SAMPLES_2X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/Asset+4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # set current layer\n",
    "    current_layer = Reshape((SIZE,SIZE,CHANNELS))(x)\n",
    "    \n",
    "    # convolution layers\n",
    "    for layer, n_filters in enumerate(FILTERS):\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        \n",
    "        current_layer = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)(current_layer)\n",
    "        current_layer = Activation(ACTIVATION)(current_layer)\n",
    "        current_layer = GroupNormalization(groups=n_filters,axis=-1)(current_layer)\n",
    "        \n",
    "        # max pooling\n",
    "        current_layer = MaxPooling2D()(current_layer)\n",
    "    \n",
    "    # grab the last shape for reconstruction\n",
    "    shape = current_layer.get_shape().as_list()\n",
    "    \n",
    "    # flatten\n",
    "    flat = Flatten()(current_layer)\n",
    "    \n",
    "    # latent vector\n",
    "    z = Dense(LATENT_DIM,activation=ACTIVATION)(flat)\n",
    "    z = GroupNormalization(groups=1,axis=-1,name='encoder')(z)\n",
    "    \n",
    "    return z, (shape[1],shape[2],shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Deep Convolutional Networks for Large-Scale Image Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1409.1556\n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/CascadingConvolutions.png\">\n",
    "\n",
    "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3×3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers.\n",
    "\n",
    "First, we incorporate three non-linear rectification layers instead of a single one, which makes the decision function more discriminative.\n",
    "\n",
    "Second, we decrease the number of parameters: assuming that both the input and the output of a\n",
    "three-layer 3 × 3 convolution stack has C channels, the stack is parametrised by (W) weights; at the same time, a single 7 × 7 conv. layer would require 81% more. This can be seen as imposing a regularisation on the 7 × 7 conv. filters, forcing them to have a decomposition through the 3 × 3 filters (with non-linearity injected in between)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/groupnorm.png\">\n",
    "\n",
    "\n",
    "The mainstream normalization technique for almost all convolutional neural networks today is Batch Normalization (BN), which has been widely adopted in the development of deep learning. Proposed by Google in 2015, BN can not only accelerate a model’s converging speed, but also alleviate problems such as Gradient Dispersion in the deep neural network, making it easier to train models.\n",
    "\n",
    "Dr. Wu and Dr. He however argue in their paper Group Normalization that normalizing with batch size has limitations, as BN cannot ensure the model accuracy rate when the batch size becomes smaller. As a result, researchers today are normalizing with large batches, which is very memory intensive, and are avoiding using limited memory to explore higher-capacity models.\n",
    "\n",
    "Dr. Wu and Dr. He believe their new GN technique is a simple but effective alternative to BN. Specifically, GN divides channels — also referred to as feature maps that look like 3D chunks of data — into groups and normalizes the features within each group. GN only exploits the layer dimensions, and its computation is independent of batch sizes.\n",
    "\n",
    "The paper reports that GN had a 10.6% lower error rate than its BN counterpart for ResNet-50 in ImageNet with a batch size of 2 samples; and matched BN performance while outperforming other normalization techniques with a regular batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfoVAE: Information Maximizing Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1706.02262v3\n",
    "\n",
    "https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/\n",
    "\n",
    "\n",
    "Maximum mean discrepancy (MMD, (Gretton et al. 2007)) is based on the idea that two distributions are identical if and only if all their moments are the same. Therefore, we can define a divergence by measuring how “different” the moments of two distributions p(z) and q(z) are. MMD can accomplish this efficiently via the kernel embedding trick:\n",
    "\n",
    "A kernel can be intuitively interpreted as a function that measures the “similarity” of two samples. It has a large value when two samples are similar, and small when they are different. For example, the Gaussian kernel considers points that are close in Euclidean space to be “similar”. A rough intuition of MMD, then, is that if two distributions are identical, then the average “similarity” between samples from each distribution, should be identical to the average “similarity” between mixed samples from both distributions.\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/kl_latent.gif\" ></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/mmd_latent.gif\" ></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = tf.shape(x)[0]\n",
    "    y_size = tf.shape(y)[0]\n",
    "    dim = tf.shape(x)[1]\n",
    "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))\n",
    "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n",
    "    return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true,y_pred):\n",
    "    epsilon = tf.random_normal(tf.stack([BATCH_SIZE, LATENT_DIM]))\n",
    "    latent_loss = compute_mmd(epsilon, y_pred)\n",
    "    return latent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/Asset+5.png\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution and Checkerboard Artifacts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://distill.pub/2016/deconv-checkerboard/\n",
    "\n",
    "When we have neural networks generate images, we often have them build them up from low resolution, high-level descriptions. This allows the network to describe the rough image and then fill in the details.\n",
    "\n",
    "In order to do this, we need some way to go from a lower resolution image to a higher one. We generally do this with the deconvolution operation. Roughly, deconvolution layers allow the model to use every point in the small image to “paint” a square in the larger one.\n",
    "\n",
    "Unfortunately, deconvolution can easily have “uneven overlap,” putting more of the metaphorical paint in some places than others. In particular, deconvolution has uneven overlap when the kernel size (the output window size) is not divisible by the stride (the spacing between points on the top). While the network could, in principle, carefully learn weights to avoid this  — as we’ll discuss in more detail later — in practice neural networks struggle to avoid it completely.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-2.png\">\n",
    "\n",
    "To avoid these artifacts, we’d like an alternative to regular deconvolution (“transposed convolution”). Unlike deconvolution, this approach to upsampling shouldn’t have artifacts as its default behavior. Ideally, it would go further, and be biased against such artifacts.\n",
    "\n",
    "One approach is to separate out upsampling to a higher resolution from convolution to compute features. For example, you might resize the image (using nearest-neighbor interpolation or bilinear interpolation) and then do a convolutional layer. This seems like a natural approach, and roughly similar methods have worked well in image super-resolution.\n",
    "\n",
    "Our experience has been that nearest-neighbor resize followed by a convolution works very well, in a wide variety of contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(z,z_g,shape=None):\n",
    "    \n",
    "    # reverse the encoder\n",
    "    filters = FILTERS[::-1]\n",
    "\n",
    "    # inflate\n",
    "    inflated = shape[0]*shape[1]*shape[2]\n",
    "    inflate = Dense(inflated,name='generator')\n",
    "    current_layer = inflate(z) ; generator = inflate(z_g)\n",
    "    \n",
    "    # reshape\n",
    "    reshape = Reshape(shape)\n",
    "    current_layer = reshape(current_layer) ; generator = reshape(generator)\n",
    "    \n",
    "    # build layers\n",
    "    for layer, n_filters in enumerate(filters):\n",
    "        \n",
    "        # upsample\n",
    "        u = SubPixelUpscaling(scale_factor=2)\n",
    "        current_layer = u(current_layer) ; generator = u(generator)\n",
    "\n",
    "        # stacked 3x3 convolutions with group normalization + activation\n",
    "        c1 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        a1 = Activation(ACTIVATION)\n",
    "        b1 = GroupNormalization(groups=int(n_filters/16),axis=-1)\n",
    "\n",
    "        current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "        current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "        current_layer = b1(current_layer) ; generator = b1(generator)\n",
    "\n",
    "        c2 = Conv2D(n_filters,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "        a2 = Activation(ACTIVATION)\n",
    "        b2 = GroupNormalization(groups=int(n_filters/16),axis=-1)\n",
    "        \n",
    "        current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "        current_layer = a2(current_layer) ; generator = a2(generator)\n",
    "        current_layer = b2(current_layer) ; generator = b2(generator)\n",
    "        \n",
    "    # output convolution + activation\n",
    "    conv = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    activation = Activation('tanh',name='decoder_dssim')\n",
    "    \n",
    "    current_layer = conv(current_layer)       ; generator = conv(generator)\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "    \n",
    "    flatten = Flatten(name='decoder')\n",
    "    decoder_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, decoder_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"https://s3.amazonaws.com/neurokinetikz/Asset%2B10-100.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Deep Residual Networks for Single Image Super-Resolution (EDSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1707.02921\n",
    "\n",
    "<img width=500 src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-18+at+8.54.43+AM.png\">\n",
    "\n",
    "Recently, the powerful capability of deep neural networks has led to dramatic improvements in SR. Since Dong et al. [4, 5] first proposed a deep learning-based SR method, various CNN architectures have been studied for SR. Kim et al. [11, 12] first introduced the residual network for training much deeper network architectures and achieved superior performance. In particular, they showed that skip connection and recursive convolution alleviate the burden of carrying identity information in the super-resolution network. Similarly to [20], Mao et al. [16] tackled the general image restoration problem with encoder-decoder networks and symmetric skip connections. In [16], they argue that those nested skip connections provide fast and improved convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(x,x_g,name='refiner'):\n",
    "    # 1x1 channel convolution\n",
    "    c1 = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    current_layer = c1(x) ; generator = c1(x_g)\n",
    "    \n",
    "    # shortcut\n",
    "    shortcut = current_layer; shortcut_g = generator\n",
    "    \n",
    "    # reshape convolution\n",
    "    c2 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(x) ; generator = c2(x_g)\n",
    "\n",
    "    # residual layers\n",
    "    for i in range(R_LAYERS):\n",
    "        current_layer, generator = residual(current_layer, generator, R_ATTENTION)\n",
    "    \n",
    "    # output convolution\n",
    "    c3 = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    current_layer = c3(current_layer); generator = c3(generator)\n",
    "    \n",
    "    # merge shortcut\n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "    \n",
    "    #activate\n",
    "    activation = Activation('tanh',name=name+'_dssim')\n",
    "    current_layer = activation(current_layer) ; generator = activation(generator)\n",
    "    \n",
    "    #flatten\n",
    "    flatten = Flatten(name=name)\n",
    "    refiner_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, refiner_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Recently, residual networks exhibit excellent performance in computer vision problems from the lowlevel to high-level tasks. Although Ledig et al. successfully applied the ResNet architecture to the super-resolution problem with SRResNet, we further improve the performance by employing better ResNet structure.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/download-3.png\">\n",
    "\n",
    "\n",
    "We remove the batch normalization layers from our network as Nah et al.[19] presented in their image deblurring work. Since batch normalization layers normalize the features, they get rid of range flexibility from networks by normalizing the features, it is better to remove them. We experimentally show that this simple modification increases the performance substantially as detailed in\n",
    "\n",
    "Furthermore, GPU memory usage is also sufficiently reduced since the batch normalization layers consume the same amount of memory as the preceding convolutional layers. Our baseline model without batch normalization layer saves approximately 40% of memory usage during training, compared to SRResNet. Consequently, we can build up a larger model that has better performance than conventional ResNet structure under limited computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(x,x_g,attention=False):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "\n",
    "    # shortcuts\n",
    "    shortcut = current_layer ; shortcut_g = generator\n",
    "\n",
    "    # conv 1\n",
    "    c1 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator)\n",
    "    \n",
    "    # activation 1\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator)\n",
    "\n",
    "    # conv 2\n",
    "    c2 = Conv2D(R_FILTERS,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "    \n",
    "    # residual scaling\n",
    "    scale = Lambda(lambda x: x * R_SCALING)\n",
    "    current_layer = scale(current_layer) ; generator = scale(generator)\n",
    "    \n",
    "    # residual attention\n",
    "    if(attention):\n",
    "        current_layer, generator = residual_attention(current_layer,generator)\n",
    "    \n",
    "    # merge shortcut\n",
    "    merge = Add()\n",
    "    current_layer = merge([current_layer, shortcut]) ; generator = merge([generator, shortcut_g])\n",
    "\n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Bottleneck Attention Module (RBAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.amazonaws.com/neurokinetikz/Asset+8.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_attention(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # shortcuts\n",
    "    shortcut = current_layer ; shortcut_g = generator\n",
    "    \n",
    "    # channel attention\n",
    "    ca, ca_g = channel_attention(current_layer, generator)\n",
    "    \n",
    "    # spatial attention\n",
    "    sa, sa_g = spatial_attention(current_layer, generator)\n",
    "    \n",
    "    # fuse channel and spatial attention\n",
    "    fuse = Add()\n",
    "    current_layer = fuse([ca,sa]); generator = fuse([ca_g,sa_g])\n",
    "    \n",
    "    # sigmoid activation\n",
    "    s = Activation(\"sigmoid\")\n",
    "    current_layer = s(current_layer) ; generator = s(generator)\n",
    "    \n",
    "    # merge fused attention with shortcut\n",
    "    m = Multiply()\n",
    "    current_layer = m([current_layer,shortcut]) ; generator = m([generator, shortcut_g])\n",
    "    \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Super-Resolution Using Very Deep Residual Channel Attention Networks (RCAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1807.02758v2\n",
    "\n",
    "<img width=\"600\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-12-16+at+11.12.08+AM.png\">\n",
    "\n",
    "To make a further step, we propose channel attention (CA) mechanism to adaptively rescale each channel-wise feature by modeling the interdependencies across feature channels. Such CA mechanism allows our proposed network to concentrate on more useful channels and enhance discriminative learning ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Attention Module for Single Image Super-Resolution (RAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1811.12043\n",
    "\n",
    "<img width=\"500\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-12-07+at+8.51.39+AM.png\">\n",
    "\n",
    "In this paper, we propose a new attention method, which is composed of new channel-wise and spatial attention mechanisms optimized for SR and a new fused attention to combine them. Based on this, we propose a new residual attention module (RAM) and a SR network using RAM (SRRAM). We provide in-depth experimental analysis of different attention mechanisms in SR. It is shown that the proposed method can construct both deep and lightweight SR networks showing improved performance in comparison to existing state-of-the-art methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # global variance pooling\n",
    "    gvp = GlobalVariancePooling2D(); reshape = Reshape((1,1,R_FILTERS))\n",
    "    current_layer = reshape(gvp(current_layer)); generator = reshape(gvp(generator))\n",
    "    \n",
    "    # squeeze\n",
    "    squeeze = Conv2D(int(R_FILTERS/R_REDUCTION),1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = squeeze(current_layer); generator = squeeze(generator);\n",
    "    \n",
    "    # excitation\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer); generator = a1(generator)\n",
    "    \n",
    "    # scaling\n",
    "    c2 = Conv2D(R_FILTERS,1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "    \n",
    "    # group normalization\n",
    "    gn = GroupNormalization(groups=1,axis=-1)\n",
    "    current_layer = gn(current_layer); generator = gn(generator)\n",
    "        \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAM: Bottleneck Attention Module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1807.06514v2\n",
    "\n",
    "<img width=\"600\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-12-16+at+10.15.09+AM.png\">\n",
    "\n",
    "In this work, we focus on the effect of attention in general deep neural networks. We propose a simple and effective attention module, named Bottleneck Attention Module (BAM), that can be integrated with any feed-forward convolutional neural networks. Our module infers an attention map along two separate pathways, channel and spatial. We place our module at each bottleneck of models where the downsampling of feature maps occurs. Our module constructs a hierarchical attention at bottlenecks with a number of parameters and it is trainable in an end-to-end manner jointly with any feed-forward models.\n",
    "\n",
    "As the channels of feature maps can be regarded as feature detectors, the two branches (spatial and channel) explicitly learn ‘what’ and ‘where’ to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(x,x_g):\n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g\n",
    "    \n",
    "    # 1x1 convolution\n",
    "    c1 = Conv2D(int(R_FILTERS/R_REDUCTION),1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer); generator = c1(generator)\n",
    "\n",
    "    # dilated convolution\n",
    "    c2 = Conv2D(int(R_FILTERS/R_REDUCTION),3,dilation_rate=R_DILATION,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator)\n",
    "\n",
    "    # dilated convolution\n",
    "    c3 = Conv2D(int(R_FILTERS/R_REDUCTION),3,dilation_rate=R_DILATION,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c3(current_layer) ; generator = c3(generator)\n",
    "\n",
    "    # 1x1 convolution\n",
    "    c4 = Conv2D(1,1,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c4(current_layer); generator = c4(generator)\n",
    "    \n",
    "    # group normalization\n",
    "    gn = GroupNormalization(groups=1,axis=-1)\n",
    "    current_layer = gn(current_layer); generator = gn(generator)\n",
    "    \n",
    "    return current_layer, generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1609.05158\n",
    "\n",
    "<img width=\"75%\" src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-23+at+10.26.45+AM.png\">\n",
    "\n",
    "Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. \n",
    "\n",
    "In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architecture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By doing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. \n",
    "\n",
    "We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x,x_g,img_g,name='super'):\n",
    "    \n",
    "    # current layer\n",
    "    current_layer = x ; generator = x_g; img_generator = img_g\n",
    "    \n",
    "    # convolution\n",
    "    c1 = Conv2D(R_FILTERS*SCALE_FACTOR*SCALE_FACTOR,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c1(current_layer) ; generator = c1(generator) ; img_generator = c1(img_generator)\n",
    "    \n",
    "    # activation\n",
    "    a1 = Activation(ACTIVATION)\n",
    "    current_layer = a1(current_layer) ; generator = a1(generator); img_generator = a1(img_generator)\n",
    "    \n",
    "    # sub-pixel upscaling\n",
    "    upscale = SubPixelUpscaling(scale_factor=SCALE_FACTOR)\n",
    "    current_layer = upscale(current_layer); generator = upscale(generator); img_generator = upscale(img_generator)\n",
    "    \n",
    "    # In practice, it is useful to have a second convolution layer after the \n",
    "    # SubPixelUpscaling layer to speed up the learning process.\n",
    "    c2 = Conv2D(R_FILTERS*SCALE_FACTOR*SCALE_FACTOR,3,padding='SAME',kernel_initializer=INITIALIZER)\n",
    "    current_layer = c2(current_layer) ; generator = c2(generator); img_generator = c2(img_generator)\n",
    "    \n",
    "    # activation\n",
    "    a2 = Activation(ACTIVATION)\n",
    "    current_layer = a2(current_layer) ; generator = a2(generator); img_generator = a2(img_generator)\n",
    "    \n",
    "    # convolution\n",
    "    c3 = Conv2D(CHANNELS,1,padding='SAME')\n",
    "    current_layer = c3(current_layer); generator = c3(generator); img_generator = c3(img_generator)\n",
    "    \n",
    "    # activation\n",
    "    a3 = Activation('tanh',name=name+\"_dssim\")\n",
    "    current_layer = a3(current_layer) ; generator = a3(generator); img_generator = a3(img_generator)\n",
    "    \n",
    "    # flatten\n",
    "    flatten = Flatten(name=name)\n",
    "    upscale_loss = flatten(current_layer)\n",
    "    \n",
    "    return current_layer, generator, img_generator, upscale_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1511.07289\n",
    "\n",
    "<img width=\"300\" style=\"float:left;\" src=\"https://blogs.mathworks.com/deep-learning/files/2017/12/defining_elu_layer_01.png\">\n",
    "\n",
    "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. \n",
    "\n",
    "In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. \n",
    "\n",
    "Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default activation\n",
    "ACTIVATION  = 'elu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters in Action! Part II — Weight Initializers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
    "\n",
    "<img width=\"300\" style=\"float:left;\" src=\"https://cdn-images-1.medium.com/max/1600/1*WLUL_bcjsNK9sXNw6nC-cg.png\">\n",
    "\n",
    "If you dug a little bit deeper, you’ve likely also found out that one should use Xavier / Glorot initialization if the activation function is a Tanh, and that He initialization is the recommended one if the activation function is a ReLU.\n",
    "\n",
    "In summary, for a ReLU activated network, the He initialization scheme using an Uniform distribution is a pretty good choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializers\n",
    "INITIALIZER = 'he_uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Generate Images with Perceptual Similarity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1511.06409\n",
    "\n",
    "<img width=\"200\" style=\"float:left;\" src=\"https://s3.amazonaws.com/neurokinetikz/download-4.png\">\n",
    "\n",
    "In this paper, we explore loss functions that, unlike MSE, MAE, and likelihoods, are grounded in human perceptual judgments. We show that these perceptual losses lead to representations are superior to other methods, both with respect to reconstructing given images, and generating novel ones. This superiority is demonstrated both in quantitative studies and human judgements ... We (also) demonstrate that perceptual losses yield a convincing win when applied to a state-of-the-art architecture for single image super-resolution.\n",
    "\n",
    "As observed in the deterministic case, MS-SSIM is better at capturing fine details than either MSE or MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 4\n",
    "SAMPLES =  np.random.permutation(FLAT)[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder/Decoder\n",
    "if (SIZE == 256):\n",
    "    FILTERS = [64,96,128,160,192,224]\n",
    "    \n",
    "elif (SIZE == 128):\n",
    "    FILTERS = [64,96,128,160,192]\n",
    "    \n",
    "elif (SIZE == 64):\n",
    "    FILTERS = [64,96,128,160]\n",
    "    \n",
    "elif (SIZE == 32):\n",
    "    FILTERS = [64,96,128]\n",
    "    \n",
    "# Residuals\n",
    "R_LAYERS  = 16\n",
    "R_FILTERS = 64\n",
    "R_SCALING = 0.01\n",
    "\n",
    "# Attention Modules\n",
    "R_ATTENTION = True\n",
    "R_REDUCTION = 4\n",
    "R_DILATION = 4\n",
    "\n",
    "# Latent dimension size\n",
    "LATENT_DIM = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 12288)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 64, 64, 3)    0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 64, 64, 64)   1792        reshape_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 64, 64, 64)   0           conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_145 (GroupN (None, 64, 64, 64)   128         activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 64, 64, 64)   36928       group_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 64, 64, 64)   0           conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_146 (GroupN (None, 64, 64, 64)   128         activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 64)   0           group_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 32, 32, 96)   55392       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 32, 32, 96)   0           conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_147 (GroupN (None, 32, 32, 96)   192         activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 32, 32, 96)   83040       group_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 32, 32, 96)   0           conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_148 (GroupN (None, 32, 32, 96)   192         activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 96)   0           group_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 16, 16, 128)  110720      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 128)  0           conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_149 (GroupN (None, 16, 16, 128)  256         activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 16, 16, 128)  147584      group_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 128)  0           conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_150 (GroupN (None, 16, 16, 128)  256         activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 128)    0           group_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 8, 8, 160)    184480      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 8, 8, 160)    0           conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_151 (GroupN (None, 8, 8, 160)    320         activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 8, 8, 160)    230560      group_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 8, 8, 160)    0           conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_152 (GroupN (None, 8, 8, 160)    320         activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 160)    0           group_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2560)         0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1311232     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder (GroupNormalization)    (None, 512)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "generator (Dense)               (None, 2560)         1313280     encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 4, 4, 160)    0           generator[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_16 (SubPixe (None, 8, 8, 40)     0           reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 8, 8, 160)    57760       sub_pixel_upscaling_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 8, 8, 160)    0           conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_153 (GroupN (None, 8, 8, 160)    320         activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 8, 8, 160)    230560      group_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 8, 8, 160)    0           conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_154 (GroupN (None, 8, 8, 160)    320         activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_17 (SubPixe (None, 16, 16, 40)   0           group_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 16, 16, 128)  46208       sub_pixel_upscaling_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 128)  0           conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_155 (GroupN (None, 16, 16, 128)  256         activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 16, 16, 128)  147584      group_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 128)  0           conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_156 (GroupN (None, 16, 16, 128)  256         activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_18 (SubPixe (None, 32, 32, 32)   0           group_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 32, 32, 96)   27744       sub_pixel_upscaling_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 96)   0           conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_157 (GroupN (None, 32, 32, 96)   192         activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 32, 32, 96)   83040       group_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 96)   0           conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_158 (GroupN (None, 32, 32, 96)   192         activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_19 (SubPixe (None, 64, 64, 24)   0           group_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 64, 64, 64)   13888       sub_pixel_upscaling_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 64, 64, 64)   0           conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_159 (GroupN (None, 64, 64, 64)   128         activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 64, 64, 64)   36928       group_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 64, 64, 64)   0           conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_160 (GroupN (None, 64, 64, 64)   128         activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 64, 64, 3)    195         group_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dssim (Activation)      (None, 64, 64, 3)    0           conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 64, 64, 64)   1792        decoder_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 64, 64, 64)   36928       conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 64, 64, 64)   0           conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 64, 64, 64)   36928       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 64, 64, 64)   0           conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_49 (G (None, 64)           0           lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 64, 64, 16)   1040        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 1, 1, 16)     1040        reshape_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 1, 1, 16)     0           conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 1, 1, 64)     1088        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 64, 64, 1)    17          conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_161 (GroupN (None, 1, 1, 64)     128         conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_162 (GroupN (None, 64, 64, 1)    2           conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 64, 64, 64)   0           group_normalization_161[0][0]    \n",
      "                                                                 group_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 64, 64, 64)   0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 64, 64, 64)   0           activation_217[0][0]             \n",
      "                                                                 lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 64, 64, 64)   0           multiply_49[0][0]                \n",
      "                                                                 conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 64, 64, 64)   36928       add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 64, 64, 64)   0           conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 64, 64, 64)   36928       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 64, 64, 64)   0           conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_50 (G (None, 64)           0           lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 64, 64, 16)   1040        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 1, 1, 16)     1040        reshape_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 1, 1, 16)     0           conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 1, 1, 64)     1088        activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 64, 64, 1)    17          conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_163 (GroupN (None, 1, 1, 64)     128         conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_164 (GroupN (None, 64, 64, 1)    2           conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 64, 64, 64)   0           group_normalization_163[0][0]    \n",
      "                                                                 group_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 64, 64, 64)   0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 64, 64, 64)   0           activation_220[0][0]             \n",
      "                                                                 lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 64, 64, 64)   0           multiply_50[0][0]                \n",
      "                                                                 add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 64, 64, 64)   36928       add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 64, 64, 64)   0           conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 64, 64, 64)   36928       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 64, 64, 64)   0           conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_51 (G (None, 64)           0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_59 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 64, 64, 16)   1040        lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 1, 1, 16)     1040        reshape_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 1, 1, 16)     0           conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 1, 1, 64)     1088        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 64, 64, 1)    17          conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_165 (GroupN (None, 1, 1, 64)     128         conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_166 (GroupN (None, 64, 64, 1)    2           conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 64, 64, 64)   0           group_normalization_165[0][0]    \n",
      "                                                                 group_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 64, 64, 64)   0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 64, 64, 64)   0           activation_223[0][0]             \n",
      "                                                                 lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 64, 64, 64)   0           multiply_51[0][0]                \n",
      "                                                                 add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 64, 64, 64)   36928       add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 64, 64, 64)   0           conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 64, 64, 64)   36928       activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 64, 64, 64)   0           conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_52 (G (None, 64)           0           lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_60 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_52[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 64, 64, 16)   1040        lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 1, 1, 16)     1040        reshape_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 1, 1, 16)     0           conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 1, 1, 64)     1088        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 64, 64, 1)    17          conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_167 (GroupN (None, 1, 1, 64)     128         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_168 (GroupN (None, 64, 64, 1)    2           conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 64, 64, 64)   0           group_normalization_167[0][0]    \n",
      "                                                                 group_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 64, 64, 64)   0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 64, 64, 64)   0           activation_226[0][0]             \n",
      "                                                                 lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 64, 64, 64)   0           multiply_52[0][0]                \n",
      "                                                                 add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 64, 64, 64)   36928       add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 64, 64, 64)   0           conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 64, 64, 64)   36928       activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 64, 64, 64)   0           conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_53 (G (None, 64)           0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_61 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_53[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 64, 64, 16)   1040        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 1, 1, 16)     1040        reshape_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 1, 1, 16)     0           conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 1, 1, 64)     1088        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 64, 64, 1)    17          conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_169 (GroupN (None, 1, 1, 64)     128         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_170 (GroupN (None, 64, 64, 1)    2           conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 64, 64, 64)   0           group_normalization_169[0][0]    \n",
      "                                                                 group_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 64, 64, 64)   0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 64, 64, 64)   0           activation_229[0][0]             \n",
      "                                                                 lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 64, 64, 64)   0           multiply_53[0][0]                \n",
      "                                                                 add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 64, 64, 64)   36928       add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 64, 64, 64)   0           conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 64, 64, 64)   36928       activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 64, 64, 64)   0           conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_54 (G (None, 64)           0           lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_62 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_54[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 64, 64, 16)   1040        lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 1, 1, 16)     1040        reshape_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 1, 1, 16)     0           conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 1, 1, 64)     1088        activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 64, 64, 1)    17          conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_171 (GroupN (None, 1, 1, 64)     128         conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_172 (GroupN (None, 64, 64, 1)    2           conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 64, 64, 64)   0           group_normalization_171[0][0]    \n",
      "                                                                 group_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 64, 64, 64)   0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 64, 64, 64)   0           activation_232[0][0]             \n",
      "                                                                 lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 64, 64, 64)   0           multiply_54[0][0]                \n",
      "                                                                 add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 64, 64, 64)   36928       add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 64, 64, 64)   0           conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 64, 64, 64)   36928       activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 64, 64, 64)   0           conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_55 (G (None, 64)           0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_63 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_55[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 64, 64, 16)   1040        lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 1, 1, 16)     1040        reshape_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 1, 1, 16)     0           conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 1, 1, 64)     1088        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 64, 64, 1)    17          conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_173 (GroupN (None, 1, 1, 64)     128         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_174 (GroupN (None, 64, 64, 1)    2           conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 64, 64, 64)   0           group_normalization_173[0][0]    \n",
      "                                                                 group_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 64, 64, 64)   0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 64, 64, 64)   0           activation_235[0][0]             \n",
      "                                                                 lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 64, 64, 64)   0           multiply_55[0][0]                \n",
      "                                                                 add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 64, 64, 64)   36928       add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 64, 64, 64)   0           conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 64, 64, 64)   36928       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 64, 64, 64)   0           conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_56 (G (None, 64)           0           lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_64 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_56[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 64, 64, 16)   1040        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 1, 1, 16)     1040        reshape_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 1, 1, 16)     0           conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 1, 1, 64)     1088        activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 64, 64, 1)    17          conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_175 (GroupN (None, 1, 1, 64)     128         conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_176 (GroupN (None, 64, 64, 1)    2           conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 64, 64, 64)   0           group_normalization_175[0][0]    \n",
      "                                                                 group_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 64, 64, 64)   0           add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 64, 64, 64)   0           activation_238[0][0]             \n",
      "                                                                 lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 64, 64, 64)   0           multiply_56[0][0]                \n",
      "                                                                 add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 64, 64, 64)   36928       add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 64, 64, 64)   0           conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 64, 64, 64)   36928       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 64, 64, 64)   0           conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_57 (G (None, 64)           0           lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_65 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_57[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 64, 64, 16)   1040        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 1, 1, 16)     1040        reshape_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 1, 1, 16)     0           conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 1, 1, 64)     1088        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 64, 64, 1)    17          conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_177 (GroupN (None, 1, 1, 64)     128         conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_178 (GroupN (None, 64, 64, 1)    2           conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 64, 64, 64)   0           group_normalization_177[0][0]    \n",
      "                                                                 group_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 64, 64, 64)   0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 64, 64, 64)   0           activation_241[0][0]             \n",
      "                                                                 lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 64, 64, 64)   0           multiply_57[0][0]                \n",
      "                                                                 add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 64, 64, 64)   36928       add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 64, 64, 64)   0           conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 64, 64, 64)   36928       activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 64, 64, 64)   0           conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_58 (G (None, 64)           0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_66 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_58[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 64, 64, 16)   1040        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 1, 1, 16)     1040        reshape_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 1, 1, 16)     0           conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 1, 1, 64)     1088        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 64, 64, 1)    17          conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_179 (GroupN (None, 1, 1, 64)     128         conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_180 (GroupN (None, 64, 64, 1)    2           conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 64, 64, 64)   0           group_normalization_179[0][0]    \n",
      "                                                                 group_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 64, 64, 64)   0           add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 64, 64, 64)   0           activation_244[0][0]             \n",
      "                                                                 lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 64, 64, 64)   0           multiply_58[0][0]                \n",
      "                                                                 add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 64, 64, 64)   36928       add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 64, 64, 64)   0           conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 64, 64, 64)   36928       activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 64, 64, 64)   0           conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_59 (G (None, 64)           0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_67 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_59[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 64, 64, 16)   1040        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 1, 1, 16)     1040        reshape_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 1, 1, 16)     0           conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 1, 1, 64)     1088        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 64, 64, 1)    17          conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_181 (GroupN (None, 1, 1, 64)     128         conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_182 (GroupN (None, 64, 64, 1)    2           conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 64, 64, 64)   0           group_normalization_181[0][0]    \n",
      "                                                                 group_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 64, 64, 64)   0           add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 64, 64, 64)   0           activation_247[0][0]             \n",
      "                                                                 lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 64, 64, 64)   0           multiply_59[0][0]                \n",
      "                                                                 add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 64, 64, 64)   36928       add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 64, 64, 64)   0           conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 64, 64, 64)   36928       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 64, 64, 64)   0           conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_60 (G (None, 64)           0           lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_68 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_60[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 64, 64, 16)   1040        lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 1, 1, 16)     1040        reshape_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 1, 1, 16)     0           conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 1, 1, 64)     1088        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 64, 64, 1)    17          conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_183 (GroupN (None, 1, 1, 64)     128         conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_184 (GroupN (None, 64, 64, 1)    2           conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 64, 64, 64)   0           group_normalization_183[0][0]    \n",
      "                                                                 group_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 64, 64, 64)   0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 64, 64, 64)   0           activation_250[0][0]             \n",
      "                                                                 lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 64, 64, 64)   0           multiply_60[0][0]                \n",
      "                                                                 add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 64, 64, 64)   36928       add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 64, 64, 64)   0           conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 64, 64, 64)   36928       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 64, 64, 64)   0           conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_61 (G (None, 64)           0           lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_69 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_61[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 64, 64, 16)   1040        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 1, 1, 16)     1040        reshape_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 1, 1, 16)     0           conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 1, 1, 64)     1088        activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 64, 64, 1)    17          conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_185 (GroupN (None, 1, 1, 64)     128         conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_186 (GroupN (None, 64, 64, 1)    2           conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 64, 64, 64)   0           group_normalization_185[0][0]    \n",
      "                                                                 group_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 64, 64, 64)   0           add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 64, 64, 64)   0           activation_253[0][0]             \n",
      "                                                                 lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 64, 64, 64)   0           multiply_61[0][0]                \n",
      "                                                                 add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 64, 64, 64)   36928       add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 64, 64, 64)   0           conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 64, 64, 64)   36928       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 64, 64, 64)   0           conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_62 (G (None, 64)           0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_62[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 64, 64, 16)   1040        lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 1, 1, 16)     1040        reshape_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 1, 1, 16)     0           conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 1, 1, 64)     1088        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 64, 64, 1)    17          conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_187 (GroupN (None, 1, 1, 64)     128         conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_188 (GroupN (None, 64, 64, 1)    2           conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 64, 64, 64)   0           group_normalization_187[0][0]    \n",
      "                                                                 group_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 64, 64, 64)   0           add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 64, 64, 64)   0           activation_256[0][0]             \n",
      "                                                                 lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 64, 64, 64)   0           multiply_62[0][0]                \n",
      "                                                                 add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 64, 64, 64)   36928       add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 64, 64, 64)   0           conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 64, 64, 64)   36928       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 64, 64, 64)   0           conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_63 (G (None, 64)           0           lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_71 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_63[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 64, 64, 16)   1040        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 1, 1, 16)     1040        reshape_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 1, 1, 16)     0           conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 1, 1, 64)     1088        activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)             (None, 64, 64, 1)    17          conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_189 (GroupN (None, 1, 1, 64)     128         conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_190 (GroupN (None, 64, 64, 1)    2           conv2d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 64, 64, 64)   0           group_normalization_189[0][0]    \n",
      "                                                                 group_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 64, 64, 64)   0           add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 64, 64, 64)   0           activation_259[0][0]             \n",
      "                                                                 lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 64, 64, 64)   0           multiply_63[0][0]                \n",
      "                                                                 add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)             (None, 64, 64, 64)   36928       add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 64, 64, 64)   0           conv2d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)             (None, 64, 64, 64)   36928       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 64, 64, 64)   0           conv2d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_variance_pooling2d_64 (G (None, 64)           0           lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_72 (Reshape)            (None, 1, 1, 64)     0           global_variance_pooling2d_64[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 64, 64, 16)   1040        lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)             (None, 1, 1, 16)     1040        reshape_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 1, 1, 16)     0           conv2d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 64, 64, 16)   2320        conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 1, 1, 64)     1088        activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 64, 64, 1)    17          conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_191 (GroupN (None, 1, 1, 64)     128         conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "group_normalization_192 (GroupN (None, 64, 64, 1)    2           conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 64, 64, 64)   0           group_normalization_191[0][0]    \n",
      "                                                                 group_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 64, 64, 64)   0           add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 64, 64, 64)   0           activation_262[0][0]             \n",
      "                                                                 lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_131 (Add)                   (None, 64, 64, 64)   0           multiply_64[0][0]                \n",
      "                                                                 add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 64, 64, 3)    195         add_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 64, 64, 3)    12          decoder_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 64, 64, 3)    0           conv2d_601[0][0]                 \n",
      "                                                                 conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "refiner_dssim (Activation)      (None, 64, 64, 3)    0           add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 64, 64, 256)  7168        refiner_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 64, 64, 256)  0           conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sub_pixel_upscaling_20 (SubPixe (None, 128, 128, 64) 0           activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 128, 128, 256 147712      sub_pixel_upscaling_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 128, 128, 256 0           conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 128, 128, 3)  771         activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "super_dssim (Activation)        (None, 128, 128, 3)  0           conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Flatten)               (None, 12288)        0           decoder_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "refiner (Flatten)               (None, 12288)        0           refiner_dssim[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "super (Flatten)                 (None, 49152)        0           super_dssim[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,590,149\n",
      "Trainable params: 5,590,149\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "X = Input(shape=(FEATURES,))\n",
    "\n",
    "# encode\n",
    "Z, shape = encode(X)\n",
    "\n",
    "# decoder input\n",
    "Z_G = Input(shape=(LATENT_DIM,))\n",
    "\n",
    "# decode\n",
    "Y, Y_G, Y_F = decode(Z,Z_G,shape)\n",
    "\n",
    "# refine\n",
    "IMG, IMG_G, IMG_F = refine(Y,Y_G)\n",
    "\n",
    "# supersizer input\n",
    "X_G = Input(shape=(SIZE,SIZE,CHANNELS))\n",
    "\n",
    "# supersize\n",
    "IMG_S, IMG_G_S, X_G_S, IMG_S_F = upsample(IMG,IMG_G,X_G)\n",
    "\n",
    "\n",
    "# model definitions\n",
    "ENCODER = Model(inputs=[X], outputs=[Z])\n",
    "DECODER = Model(inputs=[Z_G], outputs=[IMG_G])\n",
    "SUPER = Model(inputs=[Z_G], outputs=[IMG_G_S])\n",
    "SUPERSIZER = Model(inputs=[X_G], outputs=[X_G_S])\n",
    "\n",
    "# define optimizer\n",
    "ADAM = optimizers.Adam(amsgrad=True)\n",
    "\n",
    "# compile models\n",
    "ENCODER.compile(optimizer=ADAM,loss='mse')\n",
    "DECODER.compile(optimizer=ADAM,loss='mae')\n",
    "SUPER.compile(optimizer=ADAM,loss='mae')\n",
    "SUPERSIZER.compile(optimizer=ADAM,loss='mae')\n",
    "\n",
    "\n",
    "# define autoencoder\n",
    "AUTOENCODER = Model(inputs=[X], outputs=[Z,Y,Y_F,IMG,IMG_F,IMG_S,IMG_S_F])\n",
    "\n",
    "# define losses\n",
    "losses = {'encoder':vae_loss,\n",
    "          'decoder':'mse',\n",
    "          'decoder_dssim':DSSIMObjective(),\n",
    "          'refiner':'mae',\n",
    "          'refiner_dssim':DSSIMObjective(),\n",
    "          'super':'mse',\n",
    "          'super_dssim':DSSIMObjective()}\n",
    "\n",
    "# compile model\n",
    "AUTOENCODER.compile(optimizer=ADAM,loss=losses)\n",
    "\n",
    "# print summary\n",
    "AUTOENCODER.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gifit(epoch=None):\n",
    "    if (epoch % GIF_STEPS == 0):\n",
    "        print('saving gif ...')\n",
    "        z,y,yf,img,imgf,imgs,imgsf = AUTOENCODER.predict_on_batch(SAMPLES)\n",
    "        img = np.clip(127.5*(imgs+1).reshape((-1, SCALE_FACTOR*SIZE, SCALE_FACTOR*SIZE, CHANNELS)), 0, 255)\n",
    "        RECONS.append(utils.montage(img).astype(np.uint8))\n",
    "        \n",
    "        Z,Y,Y_F,IMG,IMG_F,IMG_S,IMG_S_F\n",
    "def saveit(epoch=None):\n",
    "    if ((epoch > 0) and (epoch % MODEL_STEPS == 0)):\n",
    "        print('saving model ...')\n",
    "        AUTOENCODER.save(MODEL_NAME+'-autoencoder-model.h5')\n",
    "        ENCODER.save(MODEL_NAME+'-encoder-model.h5')\n",
    "        DECODER.save(MODEL_NAME+'-generator-model.h5')\n",
    "        SUPER.save(MODEL_NAME+'-super-model.h5')\n",
    "        SUPERSIZER.save(MODEL_NAME+'-supersizer-model.h5')\n",
    "        print('done')\n",
    "       \n",
    "        \n",
    "# callbacks\n",
    "giffer = LambdaCallback(on_epoch_end=lambda epoch, logs: gifit(epoch))\n",
    "saver = LambdaCallback(on_epoch_end=lambda epoch, logs: saveit(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECONS = []\n",
    "\n",
    "EPOCHS      = 1001\n",
    "MODEL_STEPS = 1000\n",
    "GIF_STEPS   = 10\n",
    "\n",
    "# fit model\n",
    "AUTOENCODER.fit(x=FLAT,\n",
    "                y=[FLAT,IMGS,FLAT,IMGS,FLAT,IMGS_2X,FLAT_2X],\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                callbacks=[giffer,saver])\n",
    "\n",
    "# save training gif\n",
    "gif.build_gif(RECONS, saveto=MODEL_NAME+'-final'+ \"-\"+str(time.time())+'.gif')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roadtrip-256-1546710766.3303678'\n",
    "\n",
    "print('loading encoder ...', MODEL_NAME)\n",
    "ENCODER = load_model(MODEL_NAME+'-encoder-model.h5')\n",
    "\n",
    "print('loading decoder ...')\n",
    "DECODER = load_model(MODEL_NAME+'-generator-model.h5', custom_objects={'R_SCALING':R_SCALING,'GlobalVariancePooling2D':GlobalVariancePooling2D})\n",
    "\n",
    "print('loading supersizer ...')\n",
    "SUPERSIZER = load_model(MODEL_NAME+'-supersizer-model.h5')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img width=600 src=\"https://s3.amazonaws.com/neurokinetikz/Screen+Shot+2018-11-13+at+12.17.10+PM.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(index=0):\n",
    "    \n",
    "    # input\n",
    "    x = np.reshape(FLAT[index],(-1,FEATURES))\n",
    "    z = ENCODER.predict_on_batch(x)\n",
    "    \n",
    "    # output\n",
    "    img = np.reshape(DECODER.predict_on_batch(z),(-1,FEATURES))\n",
    "    img_s = np.reshape(SUPER.predict_on_batch(z),(-1,FEATURES*SCALE_FACTOR*SCALE_FACTOR))\n",
    "    \n",
    "    # reference\n",
    "    ref = IMGS[index]/2 + .5\n",
    "    ref_s = IMGS_2X[index]/2 + .5\n",
    "    \n",
    "    # denormalize\n",
    "    img = np.reshape(img/2 + .5,(SIZE,SIZE,CHANNELS))\n",
    "    img_s= np.reshape(img_s/2 + .5,(SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS))\n",
    "    \n",
    "    # print scores\n",
    "    print(\"PSNR: %.3f %.3f <> MS-SSIM: %.3f %.3f\" % ((utils.psnr(ref,img)),\n",
    "                                                     (utils.psnr(ref_s,img_s)),\n",
    "                                           (utils.MultiScaleSSIM(np.reshape(ref,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                                 np.reshape(img,(1,SIZE,SIZE,CHANNELS)),\n",
    "                                                                 max_val=1.)),\n",
    "                                            (utils.MultiScaleSSIM(np.reshape(ref_s,(1,SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS)),\n",
    "                                                                 np.reshape(img_s,(1,SCALE_FACTOR*SIZE,SCALE_FACTOR*SIZE,CHANNELS)),\n",
    "                                                                 max_val=1.))\n",
    "                                               ))\n",
    "    \n",
    "    # show images\n",
    "    utils.showImagesHorizontally(images=[ref,img])\n",
    "    utils.showImagesHorizontally(images=[ref_s,img_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct(random.randint(0,TOTAL_BATCH-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent  Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.youtube.com/watch?v=grEi3uRlSb4\n",
    "<table><tr>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-109.gif\"></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-100.gif\"></td>\n",
    "<td><img src=\"https://s3.amazonaws.com/neurokinetikz/1542113809.6163912-080.gif\"></td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_latents(n_imgs=3,steps=30):\n",
    "    rimgs = np.random.permutation(FLAT)[:n_imgs]\n",
    "    rimgs = np.append(rimgs, [rimgs[0]],axis=0)\n",
    "    latent_animation(rimgs,steps,filename=str(time.time()))\n",
    "\n",
    "def latent_animation(imgs=None,steps=None,filename=\"latent-animation\"):\n",
    "    animate(generate(get_latents(imgs,steps),filename),filename)\n",
    "    \n",
    "def get_latents(imgs,steps):\n",
    "    # get latent encodings for images\n",
    "    print('encoding latent vectors ...')\n",
    "    latents = []\n",
    "    for index,img in enumerate(imgs):\n",
    "        img = np.reshape(img,(-1,FEATURES))\n",
    "        latent = ENCODER.predict_on_batch(img)\n",
    "        latents.append(latent)\n",
    "\n",
    "    # calculate latent path\n",
    "    print('calculating latent path ...')\n",
    "    latent_path = []\n",
    "    for i in range(len(latents)-1):\n",
    "        # get latent vectors\n",
    "        l1 = latents[i] ; l2 = latents[i+1]\n",
    "\n",
    "        # calculate latent distance\n",
    "        image_distance = l2 - l1\n",
    "\n",
    "        # create the latent path\n",
    "        for j in range(steps):\n",
    "            latent_path.append(l1 + j*image_distance/steps)\n",
    "        latent_path.append(l2)\n",
    "    \n",
    "    return latent_path\n",
    "       \n",
    "    \n",
    "def generate(latent_path,filename=None):\n",
    "     # reconstruct images along the path\n",
    "    latent_path = np.reshape(latent_path,(-1,LATENT_DIM))\n",
    "    \n",
    "    print('decoding ...')\n",
    "    recons = DECODER.predict_on_batch(latent_path)\n",
    "    \n",
    "    if(filename != None):\n",
    "        print('saving decoder gif')\n",
    "        build_gif(np.asarray(recons),SIZE,filename)\n",
    "    \n",
    "    return recons\n",
    "    \n",
    "def animate(recons,filename=None):\n",
    "    print('supersizing ...')\n",
    "    chunks = SUPERSIZER.predict_on_batch(recons[:10])\n",
    "    for i in range(10,len(recons)-10,10):\n",
    "        s2 = SUPERSIZER.predict_on_batch(recons[i:i+10])\n",
    "        chunks = np.concatenate([chunks,s2])\n",
    "    \n",
    "    print('saving supersizer gif')\n",
    "#     build_gif(chunks,SIZE*SCALE_FACTOR,filename+\"-\"+str(SCALE_FACTOR)+\"x\")\n",
    "   \n",
    "    # done\n",
    "#     print(filename)\n",
    "    \n",
    "    return chunks\n",
    "    \n",
    "def build_gif(recons,size,filename='latent-animation'):\n",
    "    final = np.clip((127.5*(recons+1)).reshape((-1,size,size,CHANNELS)),0,255)\n",
    "    gif.build_gif([utils.montage([r]).astype(np.uint8) for r in final], saveto=filename+\".gif\",dpi=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LATENT_DIM=512\n",
    "for i in range(100):\n",
    "    random_latents(3,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SCALE_FACTOR=2\n",
    "GRID = 9\n",
    "N_IMGS = 3\n",
    "STEPS = 50\n",
    "\n",
    "for j in range(10):\n",
    "    grid=[]\n",
    "    for i in range(GRID):\n",
    "        imgs = np.random.permutation(FLAT)[:N_IMGS]\n",
    "        imgs = np.append(imgs, [imgs[0]],axis=0)\n",
    "\n",
    "        latent_path = get_latents(imgs,STEPS)\n",
    "        recons = animate(generate(latent_path),'')\n",
    "        final = np.clip((127.5*(recons+1)).reshape((-1,SIZE*SCALE_FACTOR,SIZE*SCALE_FACTOR,CHANNELS)),0,255)\n",
    "        grid.append(final)\n",
    "\n",
    "    rs = []\n",
    "    for img in grid:\n",
    "        rs.append([frame for frame in img])\n",
    "    rs = np.moveaxis(grid,1,0)\n",
    "    gif.build_gif([utils.montage(r).astype(np.uint8) for r in rs], saveto=str(time.time())+\".gif\",dpi=72)\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs =  np.random.permutation(FLAT)\n",
    "t = str(time.time())\n",
    "for i in range(TOTAL_BATCH):\n",
    "    print(i)\n",
    "    latent_animation([imgs[i],imgs[i+1]],100,filename=t+'-'+ ('%03d' % i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Continue Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RECONS = []\n",
    "MODEL_NAME = 'roadtrip-256-1546710766.3303678'\n",
    "MODEL_STEPS = 1\n",
    "GIF_STEPS = 1\n",
    "\n",
    "print('loading model ...')\n",
    "AUTOENCODER = load_model(MODEL_NAME+'-autoencoder-model.h5', \n",
    "                         custom_objects={'vae_loss': vae_loss,\n",
    "                                         'R_SCALING':R_SCALING,\n",
    "                                         'DSSIMObjective':DSSIMObjective(),\n",
    "                                         'GlobalVariancePooling2D':GlobalVariancePooling2D})\n",
    "\n",
    "# optimizer\n",
    "ADAM = optimizers.Adam(amsgrad=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "print('loading encoder ...', MODEL_NAME)\n",
    "ENCODER = load_model(MODEL_NAME+'-encoder-model.h5')\n",
    "ENCODER.summary()\n",
    "\n",
    "print('loading decoder ...')\n",
    "DECODER = load_model(MODEL_NAME+'-generator-model.h5', custom_objects={'R_SCALING':R_SCALING,'GlobalVariancePooling2D':GlobalVariancePooling2D})\n",
    "DECODER.summary()\n",
    "\n",
    "print('loading supersizer ...')\n",
    "SUPERSIZER = load_model(MODEL_NAME+'-supersizer-model.h5')\n",
    "SUPERSIZER.summary()\n",
    "\n",
    "# ENCODER = Model(inputs=[AUTOENCODER.input],outputs=[AUTOENCODER.get_layer(\"encoder\").output])\n",
    "# ENCODER.compile(optimizer=ADAM,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Z = ENCODER.get_layer('encoder').output\n",
    "# Y = DECODER.get_layer('generator').output\n",
    "# Y_F = DECODER.get_layer('decoder_dssim').output\n",
    "# IMG = DECODER.get_layer('refiner').output\n",
    "# IMG_F = DECODER.get_layer('refiner_dssim').output\n",
    "# IMG_S = SUPERSIZER.get_layer('super').output\n",
    "# IMG_S_F = SUPERSIZER.get_layer('super_dssim').output\n",
    "\n",
    "\n",
    "\n",
    "VAE = Model(inputs=[ENCODER.input],outputs=[SUPERSIZER(DECODER(ENCODER.output))])\n",
    "\n",
    "X = VAE.input\n",
    "\n",
    "Z = VAE.get_layer('encoder').output\n",
    "\n",
    "IMG = VAE.get_layer('model_2').get_layer('refiner_dssim').output\n",
    "\n",
    "IMG_S = VAE.output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AUTOENCODER = Model(inputs=[X,VAE.get_layer('model_2').get_layer('generator').input],outputs=[Z, IMG_S, IMG])\n",
    "\n",
    "# define optimizer\n",
    "ADAM = optimizers.Adam(amsgrad=True)\n",
    "\n",
    "\n",
    "# # define autoencoder\n",
    "# AUTOENCODER = Model(inputs=[X], outputs=[Z,Y,Y_F,IMG,IMG_F,IMG_S,IMG_S_F])\n",
    "\n",
    "# define losses\n",
    "losses = {'model_4':DSSIMObjective(),\n",
    "          'encoder':vae_loss,\n",
    "#           'decoder':'mse',\n",
    "#           'model_2':DSSIMObjective()}\n",
    "#           'refiner':'mae',\n",
    "          'refiner_dssim':DSSIMObjective()}\n",
    "#           'super':'mse',\n",
    "#           'super_dssim':DSSIMObjective()}\n",
    "\n",
    "\n",
    "# compile model\n",
    "AUTOENCODER.compile(optimizer=ADAM,loss=losses)\n",
    "\n",
    "# print summary\n",
    "AUTOENCODER.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roadtrip-256-1546710766.3303678-RESUME'\n",
    "MODEL_STEPS = 15\n",
    "GIF_STEPS = 1\n",
    "\n",
    "\n",
    "AUTOENCODER.fit(x=[FLAT,K.zeros((184,512))],\n",
    "                y=[FLAT,FLAT_2X,FLAT],\n",
    "                steps_per_epoch=46,\n",
    "                epochs=EPOCHS,\n",
    "                callbacks=[giffer,saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM=512\n",
    "for i in range(100):\n",
    "    random_latents(3,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
